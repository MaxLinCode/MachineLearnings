{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Siraj Raval\n",
    "# https://www.youtube.com/watch?v=9zhrxE5PQgY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM:\n",
    "    def __init__(self, xs, ys, rl, lr):\n",
    "        self.x = np.zeros(xs + ys)\n",
    "        self.xs = xs + ys\n",
    "        #output \n",
    "        self.y = np.zeros(ys)\n",
    "        #output size\n",
    "        self.ys = ys\n",
    "        #cell state intialized as size of prediction\n",
    "        self.cs = np.zeros(ys)\n",
    "        #how often to perform recurrence\n",
    "        self.rl = rl\n",
    "        #balance the rate of training (learning rate)\n",
    "        self.lr = lr\n",
    "        #init weight matrices for our gates\n",
    "        #forget gate\n",
    "        self.f = np.random.random((ys, xs+ys))\n",
    "        #input gate\n",
    "        self.i = np.random.random((ys, xs+ys))\n",
    "        #cell state\n",
    "        self.c = np.random.random((ys, xs+ys))\n",
    "        #output gate\n",
    "        self.o = np.random.random((ys, xs+ys))\n",
    "        #forget gate gradient\n",
    "        self.Gf = np.zeros_like(self.f)\n",
    "        #input gate gradient\n",
    "        self.Gi = np.zeros_like(self.i)\n",
    "        #cell state gradient\n",
    "        self.Gc = np.zeros_like(self.c)\n",
    "        #output gate gradient\n",
    "        self.Go = np.zeros_like(self.o)\n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(x))\n",
    "    \n",
    "    def dsigmoid(self, x):\n",
    "        return self.sigmoid(x) * (1 - self.sigmoid(x))\n",
    "    \n",
    "    def tangent(self, x):\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    def dtangent(self, x):\n",
    "        return 1 - np.tanh(x) ** 2\n",
    "    \n",
    "    def forwardProp(self):\n",
    "        f = self.sigmoid(np.dot(self.f, self.x))\n",
    "        self.cs *= f\n",
    "        i = self.sigmoid(np.dot(self.i, self.x))\n",
    "        c = self.tangent(np.dot(self.c, self.x))\n",
    "        self.cs += i * c\n",
    "        o = self.sigmoid(np.dot(self.o, self.x))\n",
    "        self.y = o * self.tangent(self.cs)\n",
    "        return self.cs, self.y, f, i, c, o\n",
    "    \n",
    "    def backProp(self, e, pcs, f, i, c, o, dfcs, dfhs):\n",
    "        #error = error + hidden state derivative. clip the value between -6 and 6.\n",
    "        e = np.clip(e + dfhs, -6, 6)\n",
    "        #multiply error by activated cell state to compute output derivative\n",
    "        do = self.tangent(self.cs) * e\n",
    "        #output update = (output deriv * activated output) * input\n",
    "        ou = np.dot(np.atleast_2d(do * self.dtangent(o)).T, np.atleast_2d(self.x))\n",
    "        #derivative of cell state = error * output * deriv of cell state + deriv cell\n",
    "        dcs = np.clip(e * o * self.dtangent(self.cs) + dfcs, -6, 6)\n",
    "        #deriv of cell = deriv cell state * input\n",
    "        dc = dcs * i\n",
    "        #cell update = deriv cell * activated cell * input\n",
    "        cu = np.dot(np.atleast_2d(dc * self.dtangent(c)).T, np.atleast_2d(self.x))\n",
    "        #deriv of input = deriv cell state * cell\n",
    "        di = dcs * c\n",
    "        #input update = (deriv input * activated input) * input\n",
    "        iu = np.dot(np.atleast_2d(di * self.dsigmoid(i)).T, np.atleast_2d(self.x))\n",
    "        #deriv forget = deriv cell state * all cell states\n",
    "        df = dcs * pcs\n",
    "        #forget update = (deriv forget * deriv forget) * input\n",
    "        fu = np.dot(np.atleast_2d(df * self.dsigmoid(f)).T, np.atleast_2d(self.x))\n",
    "        #deriv cell state = deriv cell state * forget\n",
    "        dpcs = dcs * f\n",
    "        #deriv hidden state = (deriv cell * cell) * output + deriv output * output * output deriv input * input * output + deriv forget\n",
    "        #* forget * output\n",
    "        dphs = np.dot(dc, self.c)[:self.ys] + np.dot(do, self.o)[:self.ys] + np.dot(di, self.i)[:self.ys] + np.dot(df, self.f)[:self.ys] \n",
    "        #return update gradinets for forget, input, cell, output, cell state, hidden state\n",
    "        return fu, iu, cu, ou, dpcs, dphs\n",
    "    \n",
    "    def update(self, fu, iu, cu, ou):\n",
    "        #update forget, input, cell, and output gradients\n",
    "        self.Gf = 0.9 * self.Gf + 0.1 * fu**2 \n",
    "        self.Gi = 0.9 * self.Gi + 0.1 * iu**2   \n",
    "        self.Gc = 0.9 * self.Gc + 0.1 * cu**2   \n",
    "        self.Go = 0.9 * self.Go + 0.1 * ou**2   \n",
    "        \n",
    "        #update our gates using our gradients\n",
    "        self.f -= self.lr/np.sqrt(self.Gf + 1e-8) * fu\n",
    "        self.i -= self.lr/np.sqrt(self.Gi + 1e-8) * iu\n",
    "        self.c -= self.lr/np.sqrt(self.Gc + 1e-8) * cu\n",
    "        self.o -= self.lr/np.sqrt(self.Go + 1e-8) * ou\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentNeuralNetwork:\n",
    "    # xs: seed word, ys: next word, rl: num words, eo: array of expected outputs, lr:learning rate\n",
    "    def __init__(self, xs, ys, rl, eo, lr):\n",
    "        # Initial input\n",
    "        self.x = np.zeros(xs)\n",
    "        # Input Size\n",
    "        self.xs = xs\n",
    "        # Expected Output (next word)\n",
    "        self.y = np.zeros(ys)\n",
    "        # Output Size\n",
    "        self.ys = ys\n",
    "        self.rl = rl\n",
    "        self.lr = lr\n",
    "        # Weight Matrix for interpreting results from LSTM cell\n",
    "        self.w = np.random.random((ys,ys))\n",
    "        # Matrix for RMS_prop\n",
    "        self.G = np.zeros_like(self.w)\n",
    "        # Inputs\n",
    "        self.ia = np.zeros((rl+1, xs))\n",
    "        # Cell states\n",
    "        self.ca = np.zeros((rl+1, ys))\n",
    "        # Outputs\n",
    "        self.oa = np.zeros((rl+1, ys))\n",
    "        # Hidden states\n",
    "        self.ha = np.zeros((rl+1, ys))\n",
    "        # Forget Gate\n",
    "        self.af = np.zeros((rl+1, ys))\n",
    "        # Input Gate\n",
    "        self.ai = np.zeros((rl+1, ys))\n",
    "        # Cell Gate\n",
    "        self.ac = np.zeros((rl+1, ys))\n",
    "        # Output Gate\n",
    "        self.ao = np.zeros((rl+1, ys))\n",
    "        # Expected Values\n",
    "        self.eo = np.vstack((np.zeros(eo.shape[0]), eo.T))\n",
    "        # Define LSTM\n",
    "        self.LSTM = LSTM(xs, ys, rl, lr)\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(x))\n",
    "    \n",
    "    def dsigmoid(self, x):\n",
    "        return self.sigmoid(x) * (1 - self.sigmoid(x))\n",
    "    \n",
    "    def dtangent(self, x):\n",
    "        return 1 - np.tanh(x) ** 2\n",
    "        \n",
    "    # RMS Prop\n",
    "    def update(self, u):\n",
    "        self.G = 0.9 * self.G + 0.1 * u ** 2\n",
    "        self.w -= self.lr/np.sqrt(self.G + 1e-8) * u\n",
    "        return\n",
    "    \n",
    "    def forwardProp(self):\n",
    "        for i in range(1, self.rl+1):\n",
    "            self.LSTM.x = np.hstack((self.ha[i-1], self.x))\n",
    "            cs, hs, f, inp, c, o = self.LSTM.forwardProp()\n",
    "            # Store cell state\n",
    "            self.ca[i] = cs\n",
    "            self.ha[i] = hs\n",
    "            self.af[i] = f\n",
    "            self.ai[i] = inp\n",
    "            self.ac[i] = c\n",
    "            self.ao[i] = o\n",
    "            self.oa[i] = self.sigmoid(np.dot(self.w, hs))\n",
    "            self.x = self.eo[i-1]\n",
    "            \n",
    "        return self.oa\n",
    "    \n",
    "    def backProp(self):\n",
    "        totalError = 0\n",
    "        # Cell state\n",
    "        dfcs = np.zeros(self.ys)\n",
    "        # Hidden State\n",
    "        dfhs = np.zeros(self.ys)\n",
    "        # Weight matrix\n",
    "        tu = np.zeros((self.ys, self.ys))\n",
    "        # LSTM Gradients\n",
    "        # Forget\n",
    "        tfu = np.zeros((self.ys, self.xs + self.ys))\n",
    "        # Input\n",
    "        tiu = np.zeros((self.ys, self.xs + self.ys))\n",
    "        # Cell\n",
    "        tcu = np.zeros((self.ys, self.xs + self.ys))\n",
    "        # Output\n",
    "        tou = np.zeros((self.ys, self.xs + self.ys))\n",
    "        # Backwards loop through all states\n",
    "        for i in range(self.rl, -1, -1):\n",
    "            error = self.oa[i] - self.eo[i]\n",
    "            # (error * deriv(h)) * hidden_state \n",
    "            tu = np.dot(np.atleast_2d(error * self.dsigmoid(self.oa[i])), np.atleast_2d(self.ha[i]).T)\n",
    "            # 1. error * RNN weight matrix\n",
    "            error = np.dot(error, self.w)\n",
    "            # 2. set input values of LSTM for recurrence i\n",
    "            self.LSTM.x = np.hstack((self.ha[-1], self.ia[i]))\n",
    "            # 3. set cell state for recurrence i\n",
    "            self.LSTM.cs = self.ca[i]\n",
    "            fu, iu, cu, ou, dfcs, dfhs = self.LSTM.backProp(error, self.ca[i-1], self.af[i], self.ai[i], self.ac[i], self.ao[i], dfcs, dfhs)\n",
    "            totalError += np.sum(error)\n",
    "            # Accumulate gradient updates\n",
    "            tfu += fu\n",
    "            tiu += iu\n",
    "            tcu += cu\n",
    "            tou += ou\n",
    "            \n",
    "        # Update LSTM matrices with average of total gradient update\n",
    "        self.LSTM.update(tfu/self.rl, tiu/self.rl, tcu/self.rl, tou/self.rl)\n",
    "        # Update Weight matrix with average\n",
    "        self.update(tu/self.rl)\n",
    "            \n",
    "        return totalError\n",
    "    \n",
    "    def sample(self):\n",
    "         #loop through recurrences - start at 1 so the 0th entry of all arrays will be an array of 0's\n",
    "        for i in range(1, self.rl+1):\n",
    "            #set input for LSTM cell, combination of input (previous output) and previous hidden state\n",
    "            self.LSTM.x = np.hstack((self.ha[i-1], self.x))\n",
    "            #run forward prop on the LSTM cell, retrieve cell state and hidden state\n",
    "            cs, hs, f, inp, c, o = self.LSTM.forwardProp()\n",
    "            #store input as vector\n",
    "            maxI = np.argmax(self.x)\n",
    "            self.x = np.zeros_like(self.x)\n",
    "            self.x[maxI] = 1\n",
    "            self.ia[i] = self.x #Use np.argmax?\n",
    "            #store cell states\n",
    "            self.ca[i] = cs\n",
    "            #store hidden state\n",
    "            self.ha[i] = hs\n",
    "            #forget gate\n",
    "            self.af[i] = f\n",
    "            #input gate\n",
    "            self.ai[i] = inp\n",
    "            #cell state\n",
    "            self.ac[i] = c\n",
    "            #output gate\n",
    "            self.ao[i] = o\n",
    "            #calculate output by multiplying hidden state with weight matrix\n",
    "            self.oa[i] = self.sigmoid(np.dot(self.w, hs))\n",
    "            #compute new input\n",
    "            maxI = np.argmax(self.oa[i])\n",
    "            newX = np.zeros_like(self.x)\n",
    "            newX[maxI] = 1\n",
    "            self.x = newX\n",
    "        #return all outputs    \n",
    "        return self.oa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadText():\n",
    "    #open text and return input and output data (series of words)\n",
    "    with open(\"sherlock.txt\", \"r\") as text_file:\n",
    "        data = text_file.read()\n",
    "    # Shorten data\n",
    "    data = data[0:10000]\n",
    "    text = list(data)\n",
    "    outputSize = len(text)\n",
    "    data = list(set(text))\n",
    "    uniqueWords, dataSize = len(data), len(data) \n",
    "    returnData = np.zeros((uniqueWords, dataSize))\n",
    "    for i in range(0, dataSize):\n",
    "        returnData[i][i] = 1\n",
    "    returnData = np.append(returnData, np.atleast_2d(data), axis=0)\n",
    "    output = np.zeros((uniqueWords, outputSize))\n",
    "    for i in range(0, outputSize):\n",
    "        index = np.where(np.asarray(data) == text[i])\n",
    "        output[:,i] = returnData[0:-1,index[0]].astype(float).ravel()  \n",
    "    return returnData, uniqueWords, output, outputSize, data\n",
    "\n",
    "#write the predicted output (series of words) to disk\n",
    "def ExportText(output, data):\n",
    "    finalOutput = np.zeros_like(output)\n",
    "    prob = np.zeros_like(output[0])\n",
    "    outputText = \"\"\n",
    "    print(len(data))\n",
    "    print(output.shape[0])\n",
    "    for i in range(0, output.shape[0]):\n",
    "        for j in range(0, output.shape[1]):\n",
    "            prob[j] = output[i][j] / np.sum(output[i])\n",
    "        outputText += np.random.choice(data, p=prob)    \n",
    "    with open(\"output.txt\", \"w\") as text_file:\n",
    "        text_file.write(outputText)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning\n",
      "Done Reading\n",
      "Error on iteration  1 :  5400883.94903\n",
      "Error on iteration  2 :  5389525.22112\n",
      "Error on iteration  3 :  5381871.36383\n",
      "Error on iteration  4 :  5375205.61648\n",
      "Error on iteration  5 :  5369165.83889\n",
      "Error on iteration  6 :  5363535.46451\n",
      "Error on iteration  7 :  5358192.12475\n",
      "Error on iteration  8 :  5353058.88138\n",
      "Error on iteration  9 :  5348083.73848\n",
      "Error on iteration  10 :  5343229.67298\n",
      "Error on iteration  11 :  5338469.25897\n",
      "Error on iteration  12 :  5333781.53951\n",
      "Error on iteration  13 :  5329150.0954\n",
      "Error on iteration  14 :  5324561.79537\n",
      "Error on iteration  15 :  5320005.95522\n",
      "Error on iteration  16 :  5315473.75357\n",
      "Error on iteration  17 :  5310957.81465\n",
      "Error on iteration  18 :  5306451.90312\n",
      "Error on iteration  19 :  5301950.69634\n",
      "Error on iteration  20 :  5297449.61119\n",
      "Error on iteration  21 :  5292944.6704\n",
      "Error on iteration  22 :  5288432.39776\n",
      "Error on iteration  23 :  5283909.73496\n",
      "Error on iteration  24 :  5279373.97482\n",
      "Error on iteration  25 :  5274822.70713\n",
      "Error on iteration  26 :  5270253.77429\n",
      "Error on iteration  27 :  5265665.23459\n",
      "Error on iteration  28 :  5261055.33173\n",
      "Error on iteration  29 :  5256422.46914\n",
      "Error on iteration  30 :  5251765.1884\n",
      "Error on iteration  31 :  5247082.15079\n",
      "Error on iteration  32 :  5242372.12161\n",
      "Error on iteration  33 :  5237633.9567\n",
      "Error on iteration  34 :  5232866.59075\n",
      "Error on iteration  35 :  5228069.02725\n",
      "Error on iteration  36 :  5223240.32969\n",
      "Error on iteration  37 :  5218379.61389\n",
      "Error on iteration  38 :  5213486.04129\n",
      "Error on iteration  39 :  5208558.81302\n",
      "Error on iteration  40 :  5203597.16474\n",
      "Error on iteration  41 :  5198600.36199\n",
      "Error on iteration  42 :  5193567.69612\n",
      "Error on iteration  43 :  5188498.48069\n",
      "Error on iteration  44 :  5183392.04821\n",
      "Error on iteration  45 :  5178247.7473\n",
      "Error on iteration  46 :  5173064.94004\n",
      "Error on iteration  47 :  5167842.99975\n",
      "Error on iteration  48 :  5162581.30887\n",
      "Error on iteration  49 :  5157279.25706\n",
      "Error on iteration  50 :  5151936.23958\n",
      "Error on iteration  51 :  5146551.65574\n",
      "Error on iteration  52 :  5141124.90749\n",
      "Error on iteration  53 :  5135655.39822\n",
      "Error on iteration  54 :  5130142.53157\n",
      "Error on iteration  55 :  5124585.71042\n",
      "Error on iteration  56 :  5118984.3359\n",
      "Error on iteration  57 :  5113337.80656\n",
      "Error on iteration  58 :  5107645.51752\n",
      "Error on iteration  59 :  5101906.85976\n",
      "Error on iteration  60 :  5096121.2194\n",
      "Error on iteration  61 :  5090287.97704\n",
      "Error on iteration  62 :  5084406.50723\n",
      "Error on iteration  63 :  5078476.17782\n",
      "Error on iteration  64 :  5072496.34949\n",
      "Error on iteration  65 :  5066466.3752\n",
      "Error on iteration  66 :  5060385.59976\n",
      "Error on iteration  67 :  5054253.35934\n",
      "Error on iteration  68 :  5048068.98104\n",
      "Error on iteration  69 :  5041831.78249\n",
      "Error on iteration  70 :  5035541.0714\n",
      "Error on iteration  71 :  5029196.14521\n",
      "Error on iteration  72 :  5022796.2907\n",
      "Error on iteration  73 :  5016340.78359\n",
      "Error on iteration  74 :  5009828.88817\n",
      "Error on iteration  75 :  5003259.85697\n",
      "Error on iteration  76 :  4996632.93037\n",
      "Error on iteration  77 :  4989947.33625\n",
      "Error on iteration  78 :  4983202.28964\n",
      "Error on iteration  79 :  4976396.99234\n",
      "Error on iteration  80 :  4969530.6326\n",
      "Error on iteration  81 :  4962602.38472\n",
      "Error on iteration  82 :  4955611.40874\n",
      "Error on iteration  83 :  4948556.85003\n",
      "Error on iteration  84 :  4941437.83894\n",
      "Error on iteration  85 :  4934253.49045\n",
      "Error on iteration  86 :  4927002.90374\n",
      "Error on iteration  87 :  4919685.16189\n",
      "Error on iteration  88 :  4912299.33141\n",
      "Error on iteration  89 :  4904844.46188\n",
      "Error on iteration  90 :  4897319.58559\n",
      "Error on iteration  91 :  4889723.71704\n",
      "Error on iteration  92 :  4882055.8526\n",
      "Error on iteration  93 :  4874314.97007\n",
      "Error on iteration  94 :  4866500.02821\n",
      "Error on iteration  95 :  4858609.96634\n",
      "Error on iteration  96 :  4850643.70386\n",
      "Error on iteration  97 :  4842600.13977\n",
      "Error on iteration  98 :  4834478.15226\n",
      "Error on iteration  99 :  4826276.59815\n",
      "Error on iteration  100 :  4817994.31244\n",
      "[[ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.05939387  0.07908078  0.09549869 ...,  0.07445115  0.08276198\n",
      "   0.0909994 ]\n",
      " [ 0.42437756  0.4293518   0.43642977 ...,  0.43229241  0.43397745\n",
      "   0.43004246]\n",
      " ..., \n",
      " [ 0.3829019   0.39418098  0.40352851 ...,  0.38775027  0.40354471\n",
      "   0.39144849]\n",
      " [ 0.07219082  0.09738694  0.11288243 ...,  0.09858509  0.10307539\n",
      "   0.09910945]\n",
      " [ 0.3829019   0.39418098  0.40352851 ...,  0.38775027  0.40354471\n",
      "   0.39144849]]\n",
      "64\n",
      "10001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:30: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:31: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Writing\n",
      "Error on iteration  101 :  4809675.68426\n",
      "Error on iteration  102 :  4801170.01424\n",
      "Error on iteration  103 :  4792627.16817\n",
      "Error on iteration  104 :  4783999.41817\n",
      "Error on iteration  105 :  4775285.17479\n",
      "Error on iteration  106 :  4766482.9801\n",
      "Error on iteration  107 :  4757591.41247\n",
      "Error on iteration  108 :  4748609.05451\n",
      "Error on iteration  109 :  4739534.4791\n",
      "Error on iteration  110 :  4730366.24217\n",
      "Error on iteration  111 :  4721102.87842\n",
      "Error on iteration  112 :  4711742.8985\n",
      "Error on iteration  113 :  4702284.78693\n",
      "Error on iteration  114 :  4692727.00051\n",
      "Error on iteration  115 :  4683067.96694\n",
      "Error on iteration  116 :  4673306.08362\n",
      "Error on iteration  117 :  4663439.71654\n",
      "Error on iteration  118 :  4653467.19925\n",
      "Error on iteration  119 :  4643386.83179\n",
      "Error on iteration  120 :  4633196.87975\n",
      "Error on iteration  121 :  4622895.57323\n",
      "Error on iteration  122 :  4612481.10581\n",
      "Error on iteration  123 :  4601951.63356\n",
      "Error on iteration  124 :  4591305.27401\n",
      "Error on iteration  125 :  4580540.105\n",
      "Error on iteration  126 :  4569654.16366\n",
      "Error on iteration  127 :  4558645.44525\n",
      "Error on iteration  128 :  4547511.90195\n",
      "Error on iteration  129 :  4536251.44168\n",
      "Error on iteration  130 :  4524861.92681\n",
      "Error on iteration  131 :  4513341.17288\n",
      "Error on iteration  132 :  4501686.94714\n",
      "Error on iteration  133 :  4489896.96719\n",
      "Error on iteration  134 :  4477968.89943\n",
      "Error on iteration  135 :  4465900.35743\n",
      "Error on iteration  136 :  4453688.9003\n",
      "Error on iteration  137 :  4441332.0309\n",
      "Error on iteration  138 :  4428827.1939\n",
      "Error on iteration  139 :  4416171.77382\n",
      "Error on iteration  140 :  4403363.09286\n",
      "Error on iteration  141 :  4390398.40856\n",
      "Error on iteration  142 :  4377274.91135\n",
      "Error on iteration  143 :  4363989.72182\n",
      "Error on iteration  144 :  4350539.88786\n",
      "Error on iteration  145 :  4336922.38139\n",
      "Error on iteration  146 :  4323134.0949\n",
      "Error on iteration  147 :  4309171.8376\n",
      "Error on iteration  148 :  4295032.33112\n",
      "Error on iteration  149 :  4280712.20473\n",
      "Error on iteration  150 :  4266207.98999\n",
      "Error on iteration  151 :  4251516.11467\n",
      "Error on iteration  152 :  4236632.89582\n",
      "Error on iteration  153 :  4221554.53187\n",
      "Error on iteration  154 :  4206277.09336\n",
      "Error on iteration  155 :  4190796.51218\n",
      "Error on iteration  156 :  4175108.56874\n",
      "Error on iteration  157 :  4159208.87668\n",
      "Error on iteration  158 :  4143092.8641\n",
      "Error on iteration  159 :  4126755.75047\n",
      "Error on iteration  160 :  4110192.51725\n",
      "Error on iteration  161 :  4093397.87002\n",
      "Error on iteration  162 :  4076366.18774\n",
      "Error on iteration  163 :  4059091.45283\n",
      "Error on iteration  164 :  4041567.15015\n",
      "Error on iteration  165 :  4023786.11358\n",
      "Error on iteration  166 :  4005740.27734\n",
      "Error on iteration  167 :  3987420.24036\n",
      "Error on iteration  168 :  3968814.42311\n",
      "Error on iteration  169 :  3949907.20832\n",
      "Error on iteration  170 :  3930674.00798\n",
      "Error on iteration  171 :  3911063.68675\n",
      "Error on iteration  172 :  3890881.95995\n",
      "Error on iteration  173 :  3864865.52512\n",
      "Error on iteration  174 :  3826040.99358\n",
      "Error on iteration  175 :  3791136.88136\n",
      "Error on iteration  176 :  3758642.53432\n",
      "Error on iteration  177 :  3726602.78311\n",
      "Error on iteration  178 :  3700554.83874\n",
      "Error on iteration  179 :  3687505.11125\n",
      "Error on iteration  180 :  3672275.21656\n",
      "Error on iteration  181 :  3657705.53606\n",
      "Error on iteration  182 :  3641317.08819\n",
      "Error on iteration  183 :  3619102.51304\n",
      "Error on iteration  184 :  3600455.53041\n",
      "Error on iteration  185 :  3588265.04697\n",
      "Error on iteration  186 :  3566777.64935\n",
      "Error on iteration  187 :  3546832.1992\n",
      "Error on iteration  188 :  3533898.08585\n",
      "Error on iteration  189 :  3513429.10422\n",
      "Error on iteration  190 :  3496220.47075\n",
      "Error on iteration  191 :  3477268.04394\n",
      "Error on iteration  192 :  3460233.95222\n",
      "Error on iteration  193 :  3442640.17806\n",
      "Error on iteration  194 :  3424675.04218\n",
      "Error on iteration  195 :  3407922.43869\n",
      "Error on iteration  196 :  3389666.18773\n",
      "Error on iteration  197 :  3372031.54384\n",
      "Error on iteration  198 :  3355463.40548\n",
      "Error on iteration  199 :  3339765.40009\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-8e94ec71b30f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mRNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforwardProp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#update all our weights using our error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackProp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;31m#once our error/loss is small enough\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error on iteration \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\": \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-1dbf4d24f77d>\u001b[0m in \u001b[0;36mbackProp\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;31m# 3. set cell state for recurrence i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mca\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0mfu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mou\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfhs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackProp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mca\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mai\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mac\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mao\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m             \u001b[0mtotalError\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;31m# Accumulate gradient updates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-096cfade63c8>\u001b[0m in \u001b[0;36mbackProp\u001b[0;34m(self, e, pcs, f, i, c, o, dfcs, dfhs)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtangent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m#output update = (output deriv * activated output) * input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtangent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;31m#derivative of cell state = error * output * deriv of cell state + deriv cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mdcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mo\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtangent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdfcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Begin program    \n",
    "print(\"Beginning\")\n",
    "iterations = 5000\n",
    "learningRate = 0.001\n",
    "#load input output data (words)\n",
    "returnData, numCategories, expectedOutput, outputSize, data = LoadText()\n",
    "print(\"Done Reading\")\n",
    "#init our RNN using our hyperparams and dataset\n",
    "RNN = RecurrentNeuralNetwork(numCategories, numCategories, outputSize, expectedOutput, learningRate)\n",
    "\n",
    "#training time!\n",
    "for i in range(1, iterations):\n",
    "    #compute predicted next word\n",
    "    RNN.forwardProp()\n",
    "    #update all our weights using our error\n",
    "    error = RNN.backProp()\n",
    "    #once our error/loss is small enough\n",
    "    print(\"Error on iteration \", i, \": \", error)\n",
    "    if error > -100 and error < 100 or i % 100 == 0:\n",
    "        #we can finally define a seed word\n",
    "        seed = np.zeros_like(RNN.x)\n",
    "        maxI = np.argmax(np.random.random(RNN.x.shape))\n",
    "        seed[maxI] = 1\n",
    "        RNN.x = seed  \n",
    "        #and predict some new text!\n",
    "        output = RNN.sample()\n",
    "        print(output)    \n",
    "        #write it all to disk\n",
    "        ExportText(output, data)\n",
    "        print(\"Done Writing\")\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
